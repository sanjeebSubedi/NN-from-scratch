{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MV0liXgLUkC-"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Value:\n",
        "  def __init__(self, data, _parents=()):\n",
        "    self.data = data\n",
        "    self._parents = set(_parents)\n",
        "    self.grad = 0.0\n",
        "    self._backward = lambda: None\n",
        "\n",
        "  def verify_value(self, v):\n",
        "    return v if isinstance(v, Value) else Value(v)\n",
        "\n",
        "  def __add__(self, addend):\n",
        "    addend = self.verify_value(addend)\n",
        "    res = Value(self.data + addend.data, (self, addend))\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += res.grad\n",
        "      addend.grad += res.grad\n",
        "    res._backward = _backward\n",
        "    return res\n",
        "\n",
        "  def __radd__(self, addend):\n",
        "    return self + addend\n",
        "  \n",
        "  def __sub__(self, sh):\n",
        "    return self + (-sh)\n",
        "  \n",
        "  def __mul__(self, multiplier):\n",
        "    multiplier = self.verify_value(multiplier)\n",
        "    res = Value(self.data * multiplier.data, (self, multiplier))\n",
        "    def _backward():\n",
        "      self.grad += multiplier.data * res.grad\n",
        "      multiplier.grad += self.data * res.grad\n",
        "    res._backward = _backward\n",
        "    return res\n",
        "\n",
        "  def __rmul__(self, multiplier):\n",
        "    return self * multiplier\n",
        "\n",
        "  def __truediv__(self, divisor):\n",
        "    return self * divisor**-1\n",
        "  \n",
        "  def __neg__(self):\n",
        "    return self * -1\n",
        "\n",
        "  def __pow__(self, num):\n",
        "    res = Value(self.data**num, (self,))\n",
        "    def _backward():\n",
        "      self.grad += (num*self.data**(num-1)) * res.grad\n",
        "    res._backward = _backward\n",
        "    return res\n",
        "\n",
        "  def tanh(self):\n",
        "    e = math.exp(2*self.data)\n",
        "    e = (e - 1)/(e + 1); res = Value(e, (self,))\n",
        "    def _backward():\n",
        "      self.grad += (1 - e ** 2) * res.grad\n",
        "    res._backward = _backward\n",
        "    return res\n",
        "  \n",
        "  def exp(self):\n",
        "    x = self.data\n",
        "    out = Value(math.exp(x), (self,))\n",
        "\n",
        "    def _backward():\n",
        "      self.grad = out.data * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "  \n",
        "  def backward(self):\n",
        "    back_path = []\n",
        "    visited = set()\n",
        "\n",
        "    def back_flood(node):\n",
        "      if node not in visited:\n",
        "        visited.add(node)\n",
        "        for parent in node._parents:\n",
        "          back_flood(parent)\n",
        "        back_path.append(node)\n",
        "    back_flood(self)\n",
        "    self.grad = 1.0\n",
        "    for node in reversed(back_path):\n",
        "      node._backward()\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Value(data={self.data} grad={self.grad})\""
      ],
      "metadata": {
        "id": "MTWXZ1GYUxbM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, num_inputs):\n",
        "    self.weights = [Value(random.uniform(-1, 1)) for _ in range(num_inputs)]\n",
        "    self.bias = Value(random.uniform(-1,1))\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    sum_wx = sum((weight*inp for weight, inp in zip(self.weights, inputs)), self.bias)\n",
        "    return sum_wx.tanh()\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.weights + [self.bias]\n",
        "\n"
      ],
      "metadata": {
        "id": "4R9LwomMFAnG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "  def __init__(self, num_inputs, num_out):\n",
        "    self.neurons = [Neuron(num_inputs) for _ in range(num_out)]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    out = [neuron(x) for neuron in self.neurons]\n",
        "    return out[0] if len(out) == 1 else out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [p for neuron in self.neurons for p in neuron.parameters()]\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "ARUijwxFJY80"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "  def __init__(self, num_inputs, layer_sizes):\n",
        "    layer_sizes = [num_inputs] + layer_sizes\n",
        "    self.layers = [Layer(num_in, num_out) for num_in, num_out in zip(layer_sizes, layer_sizes[1:])]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  def parameters(self):\n",
        "    return [p for layer in self.layers for p in layer.parameters()]\n",
        "\n"
      ],
      "metadata": {
        "id": "9A4offtMKwYz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = MLP(3, [4, 4, 1])"
      ],
      "metadata": {
        "id": "P1tMB9D6QFLM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(network.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDYKFcGCw4oJ",
        "outputId": "a159862e-346d-4b1b-f453-67f8abfb09a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = [\n",
        "    [2.0, 3.0, -1.0],\n",
        "    [3.0, -1.0, 0.5],\n",
        "    [0.5, 1.0, 1.0],\n",
        "    [1.0, 1.0, -1.0]\n",
        "]\n",
        "y_true = [1.0, -1.0, -1.0, 1.0]"
      ],
      "metadata": {
        "id": "9K8CWuMMQa27"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check initial predictions \n",
        "y_preds = [network(x) for x in xs]\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HVwsJzAuijN",
        "outputId": "b5414a47-36a4-46d4-d24d-506697719a09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Value(data=0.8305384198559888 grad=0.0),\n",
              " Value(data=0.5707631053827998 grad=0.0),\n",
              " Value(data=0.2877183100727975 grad=0.0),\n",
              " Value(data=0.6663887395777967 grad=0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  # get predictions\n",
        "  y_preds = [network(x) for x in xs]\n",
        "\n",
        "  # calculate loss\n",
        "  loss = sum((y_pred - y_t)**2 for y_pred, y_t in zip(y_preds, y_true))\n",
        "  y_preds = [y.data for y in y_preds]\n",
        "  print(\"Predictions: \", y_preds)\n",
        "  \n",
        "  # Zero out gradients\n",
        "  for parameter in network.parameters():\n",
        "    parameter.grad = 0.0\n",
        "  \n",
        "  # calculate gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights\n",
        "  for param in network.parameters():\n",
        "    param.data += -0.07 * param.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZujlxhtUlXz",
        "outputId": "8cc02481-3a5a-4f84-9c27-5f49527a34d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:  [0.9907081553264047, -0.9893815517297624, -0.9837681341516026, 0.9828995647347276]\n",
            "Predictions:  [0.9907175801604258, -0.989392781888364, -0.9837857384619293, 0.9829178693448728]\n",
            "Predictions:  [0.9907269764254779, -0.9894039772970273, -0.9838032879560799, 0.9829361173065815]\n",
            "Predictions:  [0.9907363442653113, -0.9894151381329932, -0.983820782914426, 0.9829543089085763]\n",
            "Predictions:  [0.9907456838226671, -0.9894262645722446, -0.9838382236153487, 0.9829724444375338]\n",
            "Predictions:  [0.9907549952392863, -0.98943735678952, -0.9838556103352556, 0.9829905241781037]\n",
            "Predictions:  [0.990764278655919, -0.9894484149583225, -0.9838729433485995, 0.9830085484129264]\n",
            "Predictions:  [0.9907735342123324, -0.989459439250933, -0.9838902229278949, 0.9830265174226517]\n",
            "Predictions:  [0.990782762047321, -0.9894704298384198, -0.9839074493437369, 0.9830444314859564]\n",
            "Predictions:  [0.990791962298714, -0.9894813868906505, -0.9839246228648172, 0.9830622908795623]\n",
            "Predictions:  [0.9908011351033847, -0.9894923105763015, -0.9839417437579427, 0.9830800958782535]\n",
            "Predictions:  [0.9908102805972587, -0.9895032010628698, -0.9839588122880506, 0.983097846754894]\n",
            "Predictions:  [0.9908193989153221, -0.989514058516684, -0.9839758287182265, 0.9831155437804445]\n",
            "Predictions:  [0.9908284901916304, -0.9895248831029129, -0.9839927933097208, 0.98313318722398]\n",
            "Predictions:  [0.9908375545593161, -0.9895356749855774, -0.9840097063219639, 0.9831507773527058]\n",
            "Predictions:  [0.9908465921505972, -0.9895464343275598, -0.9840265680125846, 0.9831683144319748]\n",
            "Predictions:  [0.9908556030967853, -0.9895571612906152, -0.9840433786374234, 0.9831857987253035]\n",
            "Predictions:  [0.9908645875282935, -0.98956785603538, -0.9840601384505511, 0.9832032304943887]\n",
            "Predictions:  [0.990873545574644, -0.9895785187213821, -0.9840768477042817, 0.983220609999123]\n",
            "Predictions:  [0.9908824773644762, -0.9895891495070515, -0.9840935066491906, 0.9832379374976109]\n",
            "Predictions:  [0.9908913830255544, -0.9895997485497294, -0.9841101155341279, 0.9832552132461851]\n",
            "Predictions:  [0.9909002626847754, -0.9896103160056774, -0.9841266746062347, 0.9832724374994214]\n",
            "Predictions:  [0.990909116468176, -0.9896208520300882, -0.9841431841109572, 0.9832896105101541]\n",
            "Predictions:  [0.9909179445009406, -0.9896313567770932, -0.984159644292063, 0.9833067325294916]\n",
            "Predictions:  [0.9909267469074083, -0.9896418303997735, -0.9841760553916542, 0.9833238038068314]\n",
            "Predictions:  [0.9909355238110805, -0.9896522730501679, -0.9841924176501828, 0.9833408245898749]\n",
            "Predictions:  [0.990944275334628, -0.9896626848792824, -0.9842087313064648, 0.9833577951246423]\n",
            "Predictions:  [0.9909530015998984, -0.9896730660370995, -0.9842249965976948, 0.9833747156554866]\n",
            "Predictions:  [0.9909617027279228, -0.9896834166725861, -0.9842412137594595, 0.9833915864251093]\n",
            "Predictions:  [0.990970378838923, -0.9896937369337037, -0.9842573830257522, 0.9834084076745734]\n",
            "Predictions:  [0.9909790300523185, -0.9897040269674153, -0.9842735046289862, 0.9834251796433182]\n",
            "Predictions:  [0.9909876564867333, -0.9897142869196964, -0.9842895788000088, 0.9834419025691733]\n",
            "Predictions:  [0.9909962582600026, -0.9897245169355409, -0.9843056057681138, 0.9834585766883721]\n",
            "Predictions:  [0.99100483548918, -0.989734717158971, -0.9843215857610566, 0.983475202235566]\n",
            "Predictions:  [0.9910133882905432, -0.9897448877330458, -0.9843375190050659, 0.9834917794438373]\n",
            "Predictions:  [0.9910219167796015, -0.9897550287998688, -0.9843534057248575, 0.9835083085447135]\n",
            "Predictions:  [0.9910304210711021, -0.989765140500596, -0.9843692461436464, 0.9835247897681796]\n",
            "Predictions:  [0.991038901279036, -0.9897752229754446, -0.9843850404831612, 0.9835412233426921]\n",
            "Predictions:  [0.9910473575166452, -0.9897852763637008, -0.9844007889636555, 0.9835576094951913]\n",
            "Predictions:  [0.9910557898964285, -0.9897953008037271, -0.98441649180392, 0.9835739484511147]\n",
            "Predictions:  [0.9910641985301477, -0.9898052964329711, -0.984432149221297, 0.9835902404344096]\n",
            "Predictions:  [0.9910725835288343, -0.9898152633879725, -0.98444776143169, 0.9836064856675453]\n",
            "Predictions:  [0.9910809450027949, -0.9898252018043711, -0.9844633286495779, 0.9836226843715261]\n",
            "Predictions:  [0.9910892830616179, -0.9898351118169142, -0.9844788510880266, 0.9836388367659036]\n",
            "Predictions:  [0.9910975978141793, -0.9898449935594643, -0.9844943289586999, 0.9836549430687886]\n",
            "Predictions:  [0.9911058893686483, -0.9898548471650068, -0.9845097624718728, 0.9836710034968634]\n",
            "Predictions:  [0.9911141578324938, -0.9898646727656565, -0.9845251518364416, 0.9836870182653937]\n",
            "Predictions:  [0.9911224033124895, -0.9898744704926657, -0.9845404972599368, 0.9837029875882407]\n",
            "Predictions:  [0.9911306259147203, -0.9898842404764314, -0.9845557989485337, 0.9837189116778723]\n",
            "Predictions:  [0.9911388257445879, -0.9898939828465013, -0.9845710571070643, 0.9837347907453752]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mwTEaxNXdeI",
        "outputId": "ec3df67a-e39b-4996-9611-c3111da2026e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value(data=0.001086478567210565 grad=1.0)\n"
          ]
        }
      ]
    }
  ]
}
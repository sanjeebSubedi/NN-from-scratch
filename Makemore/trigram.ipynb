{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9e5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bab00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read names from file\n",
    "with open(\"names.txt\", \"r\") as f:\n",
    "    names = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5085cfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [name.strip() for name in names]\n",
    "names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd46142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the names\n",
    "import re\n",
    "names = [re.sub('[-,.]', '', name) for name in names]\n",
    "names = [re.sub(r'\\(.*\\)', '', name) for name in names]\n",
    "names = [name.lower() for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ef26cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacc06cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_set = {'.'}\n",
    "\n",
    "for name in names:\n",
    "    for l in list(name):\n",
    "        letter_set.add(l)\n",
    "        \n",
    "letter_set = sorted(list(letter_set))\n",
    "len(letter_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b7d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {letter: pos for pos, letter in enumerate(letter_set)}\n",
    "itos = {pos: letter for letter, pos in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13974487",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table = torch.ones((27, 27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec3e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    name = ['.', '.'] + list(name) + ['.']\n",
    "    for char1, char2, char3 in zip(name, name[1:], name[2:]):\n",
    "        p1, p2, p3 = stoi[char1], stoi[char2], stoi[char3]\n",
    "        lookup_table[p1, p2, p3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e937f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurences(char1, char2, char3):\n",
    "    return lookup_table[stoi[char1], stoi[char2], stoi[char3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdbcbfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4411, dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_occurences('.', '.', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691ca7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(729.0001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_table = torch.div(lookup_table, torch.sum(lookup_table, dim=2, keepdims=True))\n",
    "torch.sum(lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ad1007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  cam\n",
      "Name:  ainor\n",
      "Name:  slea\n",
      "Name:  em\n",
      "Name:  mon\n",
      "Name:  eiagianaven\n",
      "Name:  kair\n",
      "Name:  uzana\n",
      "Name:  kentham\n",
      "Name:  jara\n"
     ]
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(2147483648)\n",
    "for _ in range(10):\n",
    "    idx1, idx2 = 0, 0\n",
    "    out = []\n",
    "    while True:\n",
    "        idx3 = torch.multinomial(lookup_table[idx1, idx2], num_samples=1, replacement=True, generator=gen).item()\n",
    "        if idx3==0:\n",
    "            break\n",
    "        out.append(itos[idx3])\n",
    "        idx1 = idx2\n",
    "        idx2 = idx3\n",
    "    print(\"Name: \", \"\".join(out))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ab5498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll_loss: 2.206512451171875\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0 \n",
    "num_samples = 0\n",
    "for name in names[:2]:\n",
    "    name = ['.', '.'] + list(name) + ['.']\n",
    "    for char1, char2, char3 in zip(name, name[1:], name[2:]):\n",
    "        prob = lookup_table[stoi[char1], stoi[char2], stoi[char3]]\n",
    "        log_likelihood += torch.log(prob)\n",
    "        num_samples += 1\n",
    "nll = -log_likelihood\n",
    "print(f\"nll_loss: {nll/num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8477af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 456292\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "for name in names:\n",
    "    name = ['.', '.'] + list(name) + ['.']\n",
    "    for char1, char2, char3 in zip(name, name[1:], name[2:]):\n",
    "        xs.append([stoi[char1], stoi[char2]])\n",
    "        ys.append(stoi[char3])\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(f\"Number of samples: {xs.nelement()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8aacd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0],\n",
       "        [ 0,  5],\n",
       "        [ 5, 13],\n",
       "        ...,\n",
       "        [26, 25],\n",
       "        [25, 26],\n",
       "        [26, 24]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e9b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded inputs: torch.Size([228146, 2, 27])\n",
      "Shape of weights matrix: torch.Size([54, 27])\n"
     ]
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(214748364)\n",
    "x_oh = torch.nn.functional.one_hot(xs, num_classes=27).float()\n",
    "weights = torch.randn((54, 27), requires_grad=True)\n",
    "print(f\"Shape of encoded inputs: {x_oh.shape}\")\n",
    "print(f\"Shape of weights matrix: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddd0c84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbcc1ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 54])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_oh_reshaped = x_oh.view(x_oh.shape[0], x_oh.shape[1] * x_oh.shape[2])\n",
    "x_oh_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d41efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.380014896392822\n",
      "Loss: 3.8032491207122803\n",
      "Loss: 3.4484012126922607\n",
      "Loss: 3.2576043605804443\n",
      "Loss: 3.121537446975708\n",
      "Loss: 3.0197627544403076\n",
      "Loss: 2.9405405521392822\n",
      "Loss: 2.876847982406616\n",
      "Loss: 2.8247926235198975\n",
      "Loss: 2.7817368507385254\n",
      "Loss: 2.7457733154296875\n",
      "Loss: 2.7153985500335693\n",
      "Loss: 2.6894333362579346\n",
      "Loss: 2.666961669921875\n",
      "Loss: 2.64729380607605\n",
      "Loss: 2.6299099922180176\n",
      "Loss: 2.6144187450408936\n",
      "Loss: 2.6005194187164307\n",
      "Loss: 2.5879757404327393\n",
      "Loss: 2.576596736907959\n",
      "Loss: 2.566227912902832\n",
      "Loss: 2.5567405223846436\n",
      "Loss: 2.5480265617370605\n",
      "Loss: 2.5399954319000244\n",
      "Loss: 2.532569408416748\n",
      "Loss: 2.5256826877593994\n",
      "Loss: 2.519277811050415\n",
      "Loss: 2.513305902481079\n",
      "Loss: 2.5077242851257324\n",
      "Loss: 2.502495765686035\n",
      "Loss: 2.4975879192352295\n",
      "Loss: 2.4929721355438232\n",
      "Loss: 2.4886229038238525\n",
      "Loss: 2.484518051147461\n",
      "Loss: 2.480637311935425\n",
      "Loss: 2.476963520050049\n",
      "Loss: 2.473479747772217\n",
      "Loss: 2.470172882080078\n",
      "Loss: 2.467028856277466\n",
      "Loss: 2.464036703109741\n",
      "Loss: 2.4611854553222656\n",
      "Loss: 2.458465814590454\n",
      "Loss: 2.4558684825897217\n",
      "Loss: 2.453385829925537\n",
      "Loss: 2.451010227203369\n",
      "Loss: 2.448735475540161\n",
      "Loss: 2.4465548992156982\n",
      "Loss: 2.444462776184082\n",
      "Loss: 2.442453622817993\n",
      "Loss: 2.440523147583008\n",
      "Loss: 2.438667058944702\n",
      "Loss: 2.436879873275757\n",
      "Loss: 2.435159683227539\n",
      "Loss: 2.4335012435913086\n",
      "Loss: 2.4319021701812744\n",
      "Loss: 2.43035888671875\n",
      "Loss: 2.428868532180786\n",
      "Loss: 2.427428722381592\n",
      "Loss: 2.4260363578796387\n",
      "Loss: 2.424689769744873\n",
      "Loss: 2.423386573791504\n",
      "Loss: 2.4221243858337402\n",
      "Loss: 2.4209015369415283\n",
      "Loss: 2.4197163581848145\n",
      "Loss: 2.418566942214966\n",
      "Loss: 2.4174509048461914\n",
      "Loss: 2.4163684844970703\n",
      "Loss: 2.4153168201446533\n",
      "Loss: 2.414295196533203\n",
      "Loss: 2.413302421569824\n",
      "Loss: 2.412336587905884\n",
      "Loss: 2.4113974571228027\n",
      "Loss: 2.4104831218719482\n",
      "Loss: 2.409592866897583\n",
      "Loss: 2.408726215362549\n",
      "Loss: 2.4078822135925293\n",
      "Loss: 2.4070591926574707\n",
      "Loss: 2.406256675720215\n",
      "Loss: 2.4054746627807617\n",
      "Loss: 2.4047112464904785\n",
      "Loss: 2.4039664268493652\n",
      "Loss: 2.4032392501831055\n",
      "Loss: 2.40252947807312\n",
      "Loss: 2.401836395263672\n",
      "Loss: 2.401158571243286\n",
      "Loss: 2.4004967212677\n",
      "Loss: 2.3998496532440186\n",
      "Loss: 2.399216890335083\n",
      "Loss: 2.3985979557037354\n",
      "Loss: 2.3979926109313965\n",
      "Loss: 2.39739990234375\n",
      "Loss: 2.396820068359375\n",
      "Loss: 2.3962528705596924\n",
      "Loss: 2.3956968784332275\n",
      "Loss: 2.3951528072357178\n",
      "Loss: 2.3946192264556885\n",
      "Loss: 2.394096851348877\n",
      "Loss: 2.3935844898223877\n",
      "Loss: 2.393082618713379\n",
      "Loss: 2.392590284347534\n",
      "Loss: 2.3921074867248535\n",
      "Loss: 2.391633987426758\n",
      "Loss: 2.391170024871826\n",
      "Loss: 2.390714168548584\n",
      "Loss: 2.3902671337127686\n",
      "Loss: 2.3898279666900635\n",
      "Loss: 2.389397144317627\n",
      "Loss: 2.38897442817688\n",
      "Loss: 2.388558864593506\n",
      "Loss: 2.388151168823242\n",
      "Loss: 2.3877503871917725\n",
      "Loss: 2.3873565196990967\n",
      "Loss: 2.386969566345215\n",
      "Loss: 2.386589527130127\n",
      "Loss: 2.3862156867980957\n",
      "Loss: 2.3858482837677\n",
      "Loss: 2.3854868412017822\n",
      "Loss: 2.385132312774658\n",
      "Loss: 2.3847827911376953\n",
      "Loss: 2.384439468383789\n",
      "Loss: 2.384101629257202\n",
      "Loss: 2.3837692737579346\n",
      "Loss: 2.3834424018859863\n",
      "Loss: 2.383120059967041\n",
      "Loss: 2.3828036785125732\n",
      "Loss: 2.3824923038482666\n",
      "Loss: 2.382185459136963\n",
      "Loss: 2.3818836212158203\n",
      "Loss: 2.3815863132476807\n",
      "Loss: 2.381293296813965\n",
      "Loss: 2.381005048751831\n",
      "Loss: 2.3807215690612793\n",
      "Loss: 2.380441665649414\n",
      "Loss: 2.3801660537719727\n",
      "Loss: 2.379894495010376\n",
      "Loss: 2.3796274662017822\n",
      "Loss: 2.379364013671875\n",
      "Loss: 2.3791043758392334\n",
      "Loss: 2.3788485527038574\n",
      "Loss: 2.378596782684326\n",
      "Loss: 2.378347873687744\n",
      "Loss: 2.378103017807007\n",
      "Loss: 2.377861261367798\n",
      "Loss: 2.3776233196258545\n",
      "Loss: 2.3773884773254395\n",
      "Loss: 2.377156972885132\n",
      "Loss: 2.3769288063049316\n",
      "Loss: 2.376703977584839\n",
      "Loss: 2.376481771469116\n",
      "Loss: 2.376262664794922\n",
      "Loss: 2.376046657562256\n",
      "Loss: 2.37583327293396\n",
      "Loss: 2.3756229877471924\n",
      "Loss: 2.375415325164795\n",
      "Loss: 2.375210762023926\n",
      "Loss: 2.3750088214874268\n",
      "Loss: 2.3748090267181396\n",
      "Loss: 2.3746120929718018\n",
      "Loss: 2.374418258666992\n",
      "Loss: 2.3742263317108154\n",
      "Loss: 2.374037027359009\n",
      "Loss: 2.373849868774414\n",
      "Loss: 2.3736655712127686\n",
      "Loss: 2.373483180999756\n",
      "Loss: 2.3733034133911133\n",
      "Loss: 2.3731257915496826\n",
      "Loss: 2.372950315475464\n",
      "Loss: 2.372776746749878\n",
      "Loss: 2.372605800628662\n",
      "Loss: 2.3724365234375\n",
      "Loss: 2.372269868850708\n",
      "Loss: 2.3721046447753906\n",
      "Loss: 2.3719418048858643\n",
      "Loss: 2.3717808723449707\n",
      "Loss: 2.37162184715271\n",
      "Loss: 2.371464729309082\n",
      "Loss: 2.3713090419769287\n",
      "Loss: 2.3711557388305664\n",
      "Loss: 2.371004104614258\n",
      "Loss: 2.370854139328003\n",
      "Loss: 2.370706081390381\n",
      "Loss: 2.3705594539642334\n",
      "Loss: 2.3704144954681396\n",
      "Loss: 2.370271682739258\n",
      "Loss: 2.3701300621032715\n",
      "Loss: 2.369990348815918\n",
      "Loss: 2.36985182762146\n",
      "Loss: 2.3697152137756348\n",
      "Loss: 2.369580030441284\n",
      "Loss: 2.369446277618408\n",
      "Loss: 2.369314193725586\n",
      "Loss: 2.369183301925659\n",
      "Loss: 2.369053840637207\n",
      "Loss: 2.3689258098602295\n",
      "Loss: 2.368799924850464\n",
      "Loss: 2.3686745166778564\n",
      "Loss: 2.3685507774353027\n",
      "Loss: 2.3684279918670654\n",
      "Loss: 2.368307113647461\n",
      "Loss: 2.368187427520752\n",
      "Loss: 2.3680686950683594\n",
      "Loss: 2.3679513931274414\n",
      "Loss: 2.367835283279419\n",
      "Loss: 2.367720365524292\n",
      "Loss: 2.3676068782806396\n",
      "Loss: 2.367494583129883\n",
      "Loss: 2.3673832416534424\n",
      "Loss: 2.3672728538513184\n",
      "Loss: 2.36716365814209\n",
      "Loss: 2.367055892944336\n",
      "Loss: 2.3669493198394775\n",
      "Loss: 2.3668432235717773\n",
      "Loss: 2.366738796234131\n",
      "Loss: 2.366635322570801\n",
      "Loss: 2.366532802581787\n",
      "Loss: 2.3664309978485107\n",
      "Loss: 2.366330623626709\n",
      "Loss: 2.3662312030792236\n",
      "Loss: 2.3661322593688965\n",
      "Loss: 2.366034984588623\n",
      "Loss: 2.365938186645508\n",
      "Loss: 2.365842819213867\n",
      "Loss: 2.365748167037964\n",
      "Loss: 2.3656539916992188\n",
      "Loss: 2.3655612468719482\n",
      "Loss: 2.365469217300415\n",
      "Loss: 2.3653781414031982\n",
      "Loss: 2.365288019180298\n",
      "Loss: 2.365198850631714\n",
      "Loss: 2.365109920501709\n",
      "Loss: 2.365022659301758\n",
      "Loss: 2.3649351596832275\n",
      "Loss: 2.364849090576172\n",
      "Loss: 2.3647642135620117\n",
      "Loss: 2.3646795749664307\n",
      "Loss: 2.364595890045166\n",
      "Loss: 2.3645129203796387\n",
      "Loss: 2.3644304275512695\n",
      "Loss: 2.364349126815796\n",
      "Loss: 2.3642687797546387\n",
      "Loss: 2.3641889095306396\n",
      "Loss: 2.364109516143799\n",
      "Loss: 2.3640310764312744\n",
      "Loss: 2.363953113555908\n",
      "Loss: 2.3638761043548584\n",
      "Loss: 2.363800048828125\n",
      "Loss: 2.3637242317199707\n",
      "Loss: 2.3636491298675537\n",
      "Loss: 2.363574981689453\n",
      "Loss: 2.3635010719299316\n",
      "Loss: 2.3634281158447266\n",
      "Loss: 2.3633553981781006\n",
      "Loss: 2.363284111022949\n",
      "Loss: 2.3632125854492188\n",
      "Loss: 2.3631420135498047\n",
      "Loss: 2.363071918487549\n",
      "Loss: 2.3630030155181885\n",
      "Loss: 2.3629343509674072\n",
      "Loss: 2.362865924835205\n",
      "Loss: 2.3627984523773193\n",
      "Loss: 2.362731456756592\n",
      "Loss: 2.3626651763916016\n",
      "Loss: 2.3625991344451904\n",
      "Loss: 2.3625340461730957\n",
      "Loss: 2.36246919631958\n",
      "Loss: 2.362405300140381\n",
      "Loss: 2.3623414039611816\n",
      "Loss: 2.3622782230377197\n",
      "Loss: 2.362215757369995\n",
      "Loss: 2.3621535301208496\n",
      "Loss: 2.3620920181274414\n",
      "Loss: 2.362030506134033\n",
      "Loss: 2.3619704246520996\n",
      "Loss: 2.361910343170166\n",
      "Loss: 2.3618509769439697\n",
      "Loss: 2.3617916107177734\n",
      "Loss: 2.3617331981658936\n",
      "Loss: 2.3616750240325928\n",
      "Loss: 2.361617088317871\n",
      "Loss: 2.3615598678588867\n",
      "Loss: 2.3615031242370605\n",
      "Loss: 2.3614470958709717\n",
      "Loss: 2.361391067504883\n",
      "Loss: 2.361335515975952\n",
      "Loss: 2.361280918121338\n",
      "Loss: 2.3612263202667236\n",
      "Loss: 2.3611719608306885\n",
      "Loss: 2.3611185550689697\n",
      "Loss: 2.361065149307251\n",
      "Loss: 2.3610124588012695\n",
      "Loss: 2.360960006713867\n",
      "Loss: 2.360907793045044\n",
      "Loss: 2.360856294631958\n",
      "Loss: 2.360805034637451\n",
      "Loss: 2.3607540130615234\n",
      "Loss: 2.360703945159912\n",
      "Loss: 2.3606536388397217\n",
      "Loss: 2.3606042861938477\n",
      "Loss: 2.3605549335479736\n",
      "Loss: 2.360506057739258\n",
      "Loss: 2.360457420349121\n",
      "Loss: 2.3604092597961426\n",
      "Loss: 2.3603615760803223\n",
      "Loss: 2.360313892364502\n",
      "Loss: 2.360266923904419\n",
      "Loss: 2.360220193862915\n",
      "Loss: 2.3601739406585693\n",
      "Loss: 2.3601279258728027\n",
      "Loss: 2.3600823879241943\n",
      "Loss: 2.360037088394165\n",
      "Loss: 2.3599917888641357\n",
      "Loss: 2.3599472045898438\n",
      "Loss: 2.3599023818969727\n",
      "Loss: 2.359858989715576\n",
      "Loss: 2.3598148822784424\n",
      "Loss: 2.359771728515625\n",
      "Loss: 2.3597288131713867\n",
      "Loss: 2.3596856594085693\n",
      "Loss: 2.3596434593200684\n",
      "Loss: 2.3596012592315674\n",
      "Loss: 2.3595592975616455\n",
      "Loss: 2.359517812728882\n",
      "Loss: 2.3594765663146973\n",
      "Loss: 2.359435558319092\n",
      "Loss: 2.3593950271606445\n",
      "Loss: 2.3593544960021973\n",
      "Loss: 2.3593146800994873\n",
      "Loss: 2.3592748641967773\n",
      "Loss: 2.3592350482940674\n",
      "Loss: 2.359196186065674\n",
      "Loss: 2.359156847000122\n",
      "Loss: 2.3591184616088867\n",
      "Loss: 2.3590798377990723\n",
      "Loss: 2.359042167663574\n",
      "Loss: 2.359004020690918\n",
      "Loss: 2.358966588973999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.358928918838501\n",
      "Loss: 2.3588919639587402\n",
      "Loss: 2.3588552474975586\n",
      "Loss: 2.358818292617798\n",
      "Loss: 2.3587820529937744\n",
      "Loss: 2.358746290206909\n",
      "Loss: 2.358710289001465\n",
      "Loss: 2.3586747646331787\n",
      "Loss: 2.3586394786834717\n",
      "Loss: 2.3586044311523438\n",
      "Loss: 2.358569622039795\n",
      "Loss: 2.358534812927246\n",
      "Loss: 2.3585007190704346\n",
      "Loss: 2.358466386795044\n",
      "Loss: 2.3584325313568115\n",
      "Loss: 2.3583991527557373\n",
      "Loss: 2.358365535736084\n",
      "Loss: 2.358332395553589\n",
      "Loss: 2.3582990169525146\n",
      "Loss: 2.3582661151885986\n",
      "Loss: 2.3582334518432617\n",
      "Loss: 2.358201265335083\n",
      "Loss: 2.3581693172454834\n",
      "Loss: 2.3581371307373047\n",
      "Loss: 2.358105182647705\n",
      "Loss: 2.3580737113952637\n",
      "Loss: 2.3580427169799805\n",
      "Loss: 2.358011484146118\n",
      "Loss: 2.357980728149414\n",
      "Loss: 2.35794997215271\n",
      "Loss: 2.357919216156006\n",
      "Loss: 2.357889175415039\n",
      "Loss: 2.3578591346740723\n",
      "Loss: 2.3578290939331055\n",
      "Loss: 2.3577992916107178\n",
      "Loss: 2.3577699661254883\n",
      "Loss: 2.3577404022216797\n",
      "Loss: 2.3577115535736084\n",
      "Loss: 2.357682228088379\n",
      "Loss: 2.3576533794403076\n",
      "Loss: 2.3576252460479736\n",
      "Loss: 2.3575963973999023\n",
      "Loss: 2.3575682640075684\n",
      "Loss: 2.3575403690338135\n",
      "Loss: 2.3575124740600586\n",
      "Loss: 2.357484817504883\n",
      "Loss: 2.357456922531128\n",
      "Loss: 2.3574299812316895\n",
      "Loss: 2.3574025630950928\n",
      "Loss: 2.3573758602142334\n",
      "Loss: 2.357348918914795\n",
      "Loss: 2.3573222160339355\n",
      "Loss: 2.3572957515716553\n",
      "Loss: 2.357269287109375\n",
      "Loss: 2.357243061065674\n",
      "Loss: 2.3572170734405518\n",
      "Loss: 2.3571908473968506\n",
      "Loss: 2.357165575027466\n",
      "Loss: 2.357139825820923\n",
      "Loss: 2.357114553451538\n",
      "Loss: 2.3570895195007324\n",
      "Loss: 2.3570642471313477\n",
      "Loss: 2.357039451599121\n",
      "Loss: 2.3570146560668945\n",
      "Loss: 2.356990098953247\n",
      "Loss: 2.3569653034210205\n",
      "Loss: 2.356940746307373\n",
      "Loss: 2.356917142868042\n",
      "Loss: 2.3568930625915527\n",
      "Loss: 2.3568692207336426\n",
      "Loss: 2.3568453788757324\n",
      "Loss: 2.3568217754364014\n",
      "Loss: 2.3567981719970703\n",
      "Loss: 2.3567750453948975\n",
      "Loss: 2.3567514419555664\n",
      "Loss: 2.3567285537719727\n",
      "Loss: 2.356706142425537\n",
      "Loss: 2.3566832542419434\n",
      "Loss: 2.3566606044769287\n",
      "Loss: 2.356637954711914\n",
      "Loss: 2.3566157817840576\n",
      "Loss: 2.356593370437622\n",
      "Loss: 2.3565711975097656\n",
      "Loss: 2.3565492630004883\n",
      "Loss: 2.35652756690979\n",
      "Loss: 2.356505870819092\n",
      "Loss: 2.3564839363098145\n",
      "Loss: 2.3564624786376953\n",
      "Loss: 2.3564412593841553\n",
      "Loss: 2.356419801712036\n",
      "Loss: 2.356398582458496\n",
      "Loss: 2.3563780784606934\n",
      "Loss: 2.3563570976257324\n",
      "Loss: 2.3563363552093506\n",
      "Loss: 2.356315851211548\n",
      "Loss: 2.356295347213745\n",
      "Loss: 2.3562748432159424\n",
      "Loss: 2.3562543392181396\n",
      "Loss: 2.356234550476074\n",
      "Loss: 2.3562145233154297\n",
      "Loss: 2.3561947345733643\n",
      "Loss: 2.356174945831299\n",
      "Loss: 2.3561553955078125\n",
      "Loss: 2.356135606765747\n",
      "Loss: 2.3561160564422607\n",
      "Loss: 2.3560965061187744\n",
      "Loss: 2.3560774326324463\n",
      "Loss: 2.356058359146118\n",
      "Loss: 2.35603928565979\n",
      "Loss: 2.356020212173462\n",
      "Loss: 2.356001377105713\n",
      "Loss: 2.355982542037964\n",
      "Loss: 2.355964183807373\n",
      "Loss: 2.3559460639953613\n",
      "Loss: 2.3559272289276123\n",
      "Loss: 2.3559088706970215\n",
      "Loss: 2.3558907508850098\n",
      "Loss: 2.355872631072998\n",
      "Loss: 2.3558547496795654\n",
      "Loss: 2.3558366298675537\n",
      "Loss: 2.3558189868927\n",
      "Loss: 2.3558011054992676\n",
      "Loss: 2.355783224105835\n",
      "Loss: 2.3557660579681396\n",
      "Loss: 2.3557486534118652\n",
      "Loss: 2.355731248855591\n",
      "Loss: 2.3557138442993164\n",
      "Loss: 2.355696678161621\n",
      "Loss: 2.355679750442505\n",
      "Loss: 2.3556628227233887\n",
      "Loss: 2.3556458950042725\n",
      "Loss: 2.3556289672851562\n",
      "Loss: 2.3556125164031982\n",
      "Loss: 2.3555960655212402\n",
      "Loss: 2.355579376220703\n",
      "Loss: 2.355562925338745\n",
      "Loss: 2.355546474456787\n",
      "Loss: 2.3555305004119873\n",
      "Loss: 2.3555142879486084\n",
      "Loss: 2.3554983139038086\n",
      "Loss: 2.3554821014404297\n",
      "Loss: 2.35546612739563\n",
      "Loss: 2.3554506301879883\n",
      "Loss: 2.3554348945617676\n",
      "Loss: 2.3554189205169678\n",
      "Loss: 2.355403423309326\n",
      "Loss: 2.3553879261016846\n",
      "Loss: 2.355372428894043\n",
      "Loss: 2.3553574085235596\n",
      "Loss: 2.355342149734497\n",
      "Loss: 2.3553268909454346\n",
      "Loss: 2.355311870574951\n",
      "Loss: 2.3552966117858887\n",
      "Loss: 2.3552815914154053\n",
      "Loss: 2.35526704788208\n",
      "Loss: 2.355252265930176\n",
      "Loss: 2.3552374839782715\n",
      "Loss: 2.355222702026367\n",
      "Loss: 2.355208396911621\n",
      "Loss: 2.355194091796875\n",
      "Loss: 2.3551793098449707\n",
      "Loss: 2.3551647663116455\n",
      "Loss: 2.3551511764526367\n",
      "Loss: 2.3551366329193115\n",
      "Loss: 2.3551225662231445\n",
      "Loss: 2.3551082611083984\n",
      "Loss: 2.3550944328308105\n",
      "Loss: 2.3550806045532227\n",
      "Loss: 2.3550667762756348\n",
      "Loss: 2.355052947998047\n",
      "Loss: 2.355039358139038\n",
      "Loss: 2.35502552986145\n",
      "Loss: 2.3550121784210205\n",
      "Loss: 2.354998826980591\n",
      "Loss: 2.354985237121582\n",
      "Loss: 2.3549716472625732\n",
      "Loss: 2.3549582958221436\n",
      "Loss: 2.354945182800293\n",
      "Loss: 2.3549320697784424\n",
      "Loss: 2.354918956756592\n",
      "Loss: 2.3549060821533203\n",
      "Loss: 2.354893207550049\n",
      "Loss: 2.3548800945281982\n",
      "Loss: 2.354867458343506\n",
      "Loss: 2.3548548221588135\n",
      "Loss: 2.354841947555542\n",
      "Loss: 2.3548290729522705\n",
      "Loss: 2.3548169136047363\n",
      "Loss: 2.3548038005828857\n",
      "Loss: 2.3547914028167725\n",
      "Loss: 2.3547794818878174\n",
      "Loss: 2.354766845703125\n",
      "Loss: 2.35475492477417\n",
      "Loss: 2.3547425270080566\n",
      "Loss: 2.3547306060791016\n",
      "Loss: 2.3547182083129883\n",
      "Loss: 2.354706287384033\n",
      "Loss: 2.354694366455078\n",
      "Loss: 2.354682445526123\n",
      "Loss: 2.354670524597168\n",
      "Loss: 2.354658842086792\n",
      "Loss: 2.354646921157837\n",
      "Loss: 2.354635238647461\n",
      "Loss: 2.354623556137085\n",
      "Loss: 2.354612112045288\n",
      "Loss: 2.354600429534912\n",
      "Loss: 2.3545889854431152\n",
      "Loss: 2.3545777797698975\n",
      "Loss: 2.3545663356781006\n",
      "Loss: 2.3545548915863037\n",
      "Loss: 2.354543685913086\n",
      "Loss: 2.354532480239868\n",
      "Loss: 2.3545215129852295\n",
      "Loss: 2.3545103073120117\n",
      "Loss: 2.354498863220215\n",
      "Loss: 2.354487895965576\n",
      "Loss: 2.3544771671295166\n",
      "Loss: 2.354466199874878\n",
      "Loss: 2.3544552326202393\n",
      "Loss: 2.354444742202759\n",
      "Loss: 2.354434013366699\n",
      "Loss: 2.3544232845306396\n",
      "Loss: 2.354412794113159\n",
      "Loss: 2.3544015884399414\n",
      "Loss: 2.35439133644104\n",
      "Loss: 2.3543810844421387\n",
      "Loss: 2.354370594024658\n",
      "Loss: 2.3543601036071777\n",
      "Loss: 2.354349374771118\n",
      "Loss: 2.354339599609375\n",
      "Loss: 2.3543293476104736\n",
      "Loss: 2.354318857192993\n",
      "Loss: 2.354308843612671\n",
      "Loss: 2.3542988300323486\n",
      "Loss: 2.3542888164520264\n",
      "Loss: 2.354278802871704\n",
      "Loss: 2.354268789291382\n",
      "Loss: 2.3542585372924805\n",
      "Loss: 2.3542487621307373\n",
      "Loss: 2.3542392253875732\n",
      "Loss: 2.354229211807251\n",
      "Loss: 2.354219675064087\n",
      "Loss: 2.3542096614837646\n",
      "Loss: 2.3541998863220215\n",
      "Loss: 2.3541905879974365\n",
      "Loss: 2.3541810512542725\n",
      "Loss: 2.3541715145111084\n",
      "Loss: 2.3541619777679443\n",
      "Loss: 2.3541526794433594\n",
      "Loss: 2.354142904281616\n",
      "Loss: 2.3541338443756104\n",
      "Loss: 2.3541245460510254\n",
      "Loss: 2.3541150093078613\n",
      "Loss: 2.3541061878204346\n",
      "Loss: 2.3540968894958496\n",
      "Loss: 2.3540873527526855\n",
      "Loss: 2.354078531265259\n",
      "Loss: 2.354069232940674\n",
      "Loss: 2.354060649871826\n",
      "Loss: 2.354051351547241\n",
      "Loss: 2.3540427684783936\n",
      "Loss: 2.3540334701538086\n",
      "Loss: 2.354024887084961\n",
      "Loss: 2.354015827178955\n",
      "Loss: 2.3540070056915283\n",
      "Loss: 2.3539984226226807\n",
      "Loss: 2.353989601135254\n",
      "Loss: 2.3539810180664062\n",
      "Loss: 2.3539721965789795\n",
      "Loss: 2.35396409034729\n",
      "Loss: 2.353955030441284\n",
      "Loss: 2.3539466857910156\n",
      "Loss: 2.353938102722168\n",
      "Loss: 2.3539297580718994\n",
      "Loss: 2.3539209365844727\n",
      "Loss: 2.353912591934204\n",
      "Loss: 2.3539042472839355\n",
      "Loss: 2.353895902633667\n",
      "Loss: 2.3538877964019775\n",
      "Loss: 2.353879690170288\n",
      "Loss: 2.3538715839385986\n",
      "Loss: 2.35386323928833\n",
      "Loss: 2.3538551330566406\n",
      "Loss: 2.3538472652435303\n",
      "Loss: 2.353839159011841\n",
      "Loss: 2.3538308143615723\n",
      "Loss: 2.353822708129883\n",
      "Loss: 2.3538150787353516\n",
      "Loss: 2.353807210922241\n",
      "Loss: 2.353799343109131\n",
      "Loss: 2.3537914752960205\n",
      "Loss: 2.3537838459014893\n",
      "Loss: 2.3537757396698\n",
      "Loss: 2.3537681102752686\n",
      "Loss: 2.353760004043579\n",
      "Loss: 2.353752851486206\n",
      "Loss: 2.3537449836730957\n",
      "Loss: 2.3537373542785645\n",
      "Loss: 2.353729724884033\n",
      "Loss: 2.353722333908081\n",
      "Loss: 2.35371470451355\n",
      "Loss: 2.3537068367004395\n",
      "Loss: 2.3536994457244873\n",
      "Loss: 2.353692054748535\n",
      "Loss: 2.353684902191162\n",
      "Loss: 2.35367751121521\n",
      "Loss: 2.353670120239258\n",
      "Loss: 2.3536627292633057\n",
      "Loss: 2.3536553382873535\n",
      "Loss: 2.3536481857299805\n",
      "Loss: 2.3536410331726074\n",
      "Loss: 2.3536338806152344\n",
      "Loss: 2.3536267280578613\n",
      "Loss: 2.3536195755004883\n",
      "Loss: 2.3536124229431152\n",
      "Loss: 2.353605270385742\n",
      "Loss: 2.3535983562469482\n",
      "Loss: 2.353591203689575\n",
      "Loss: 2.3535842895507812\n",
      "Loss: 2.353577136993408\n",
      "Loss: 2.3535702228546143\n",
      "Loss: 2.3535635471343994\n",
      "Loss: 2.3535566329956055\n",
      "Loss: 2.3535499572753906\n",
      "Loss: 2.353543281555176\n",
      "Loss: 2.353536367416382\n",
      "Loss: 2.353529214859009\n",
      "Loss: 2.353522539138794\n",
      "Loss: 2.353515863418579\n",
      "Loss: 2.3535091876983643\n",
      "Loss: 2.3535025119781494\n",
      "Loss: 2.3534958362579346\n",
      "Loss: 2.353489637374878\n",
      "Loss: 2.353482723236084\n",
      "Loss: 2.3534765243530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3534698486328125\n",
      "Loss: 2.3534634113311768\n",
      "Loss: 2.353456735610962\n",
      "Loss: 2.3534505367279053\n",
      "Loss: 2.3534438610076904\n",
      "Loss: 2.353437662124634\n",
      "Loss: 2.353430986404419\n",
      "Loss: 2.3534250259399414\n",
      "Loss: 2.3534185886383057\n",
      "Loss: 2.353412389755249\n",
      "Loss: 2.3534059524536133\n",
      "Loss: 2.3533997535705566\n",
      "Loss: 2.353393793106079\n",
      "Loss: 2.3533873558044434\n",
      "Loss: 2.353381395339966\n",
      "Loss: 2.35337495803833\n",
      "Loss: 2.3533689975738525\n",
      "Loss: 2.353363275527954\n",
      "Loss: 2.3533568382263184\n",
      "Loss: 2.3533506393432617\n",
      "Loss: 2.353344678878784\n",
      "Loss: 2.3533387184143066\n",
      "Loss: 2.353332996368408\n",
      "Loss: 2.3533270359039307\n",
      "Loss: 2.3533213138580322\n",
      "Loss: 2.3533151149749756\n",
      "Loss: 2.353309392929077\n",
      "Loss: 2.3533034324645996\n",
      "Loss: 2.353297710418701\n"
     ]
    }
   ],
   "source": [
    "for _ in range(700):\n",
    "    logits = torch.matmul(x_oh_reshaped, weights)\n",
    "    counts = logits.exp()\n",
    "    probs = torch.div(counts, torch.sum(counts, dim=1, keepdims=True))\n",
    "    loss = -probs[torch.arange(xs.shape[0]), ys].log().mean() + 0.01 * (weights ** 2).mean()\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    weights.grad = None\n",
    "    loss.backward()\n",
    "    weights.data += -30 * weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6805dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can\n",
      "ahior\n",
      "slea\n",
      "em\n",
      "molariagialaven\n",
      "kali\n",
      "ustia\n",
      "kentham\n",
      "jara\n",
      "cyl\n"
     ]
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(2147483648)\n",
    "for _ in range(10):\n",
    "    out = []\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    \n",
    "    while True:\n",
    "        x_enc_1 = torch.nn.functional.one_hot(torch.tensor([idx1]), num_classes=27).float()\n",
    "        x_enc_2 = torch.nn.functional.one_hot(torch.tensor([idx2]), num_classes=27).float()\n",
    "        \n",
    "        logits = torch.matmul(torch.hstack((x_enc_1, x_enc_2)), weights)\n",
    "        counts = logits.exp()\n",
    "        probs = torch.div(counts, torch.sum(counts, dim=1, keepdims=True))\n",
    "        \n",
    "        idx3 = torch.multinomial(probs, num_samples=1, replacement=True, generator=gen).item()\n",
    "        if idx3 == 0:\n",
    "            break\n",
    "        idx1 = idx2\n",
    "        idx2 = idx3\n",
    "        out.append(itos[idx3])\n",
    "        \n",
    "    print(\"\".join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
